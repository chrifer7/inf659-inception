{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'inception_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-321cd07b5533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage_processing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0minception_model\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mslim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mslim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'inception_model'"
     ]
    }
   ],
   "source": [
    "# Copyright 2016 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Inception-v3 expressed in TensorFlow-Slim.\n",
    "\n",
    "  Usage:\n",
    "\n",
    "  # Parameters for BatchNorm.\n",
    "  batch_norm_params = {\n",
    "      # Decay for the batch_norm moving averages.\n",
    "      'decay': BATCHNORM_MOVING_AVERAGE_DECAY,\n",
    "      # epsilon to prevent 0s in variance.\n",
    "      'epsilon': 0.001,\n",
    "  }\n",
    "  # Set weight_decay for weights in Conv and FC layers.\n",
    "  with slim.arg_scope([slim.ops.conv2d, slim.ops.fc], weight_decay=0.00004):\n",
    "    with slim.arg_scope([slim.ops.conv2d],\n",
    "                        stddev=0.1,\n",
    "                        activation=tf.nn.relu,\n",
    "                        batch_norm_params=batch_norm_params):\n",
    "      # Force all Variables to reside on the CPU.\n",
    "      with slim.arg_scope([slim.variables.variable], device='/cpu:0'):\n",
    "        logits, endpoints = slim.inception.inception_v3(\n",
    "            images,\n",
    "            dropout_keep_prob=0.8,\n",
    "            num_classes=num_classes,\n",
    "            is_training=for_training,\n",
    "            restore_logits=restore_logits,\n",
    "            scope=scope)\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "from datetime import datetime\n",
    "import os.path\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import image_processing\n",
    "import inception_model as inception\n",
    "\n",
    "from slim import slim\n",
    "from slim import ops\n",
    "from slim import scopes\n",
    "\n",
    "\n",
    "def inception_v3(inputs,\n",
    "                 dropout_keep_prob=0.8,\n",
    "                 num_classes=1000,\n",
    "                 is_training=True,\n",
    "                 restore_logits=True,\n",
    "                 scope=''):\n",
    "  \"\"\"Latest Inception from http://arxiv.org/abs/1512.00567.\n",
    "\n",
    "    \"Rethinking the Inception Architecture for Computer Vision\"\n",
    "\n",
    "    Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens,\n",
    "    Zbigniew Wojna\n",
    "\n",
    "  Args:\n",
    "    inputs: a tensor of size [batch_size, height, width, channels].\n",
    "    dropout_keep_prob: dropout keep_prob.\n",
    "    num_classes: number of predicted classes.\n",
    "    is_training: whether is training or not.\n",
    "    restore_logits: whether or not the logits layers should be restored.\n",
    "      Useful for fine-tuning a model with different num_classes.\n",
    "    scope: Optional scope for name_scope.\n",
    "\n",
    "  Returns:\n",
    "    a list containing 'logits', 'aux_logits' Tensors.\n",
    "  \"\"\"\n",
    "  # end_points will collect relevant activations for external use, for example\n",
    "  # summaries or losses.\n",
    "  end_points = {}\n",
    "  with tf.name_scope(scope, 'inception_v3', [inputs]):\n",
    "    with scopes.arg_scope([ops.conv2d, ops.fc, ops.batch_norm, ops.dropout],\n",
    "                          is_training=is_training):\n",
    "      with scopes.arg_scope([ops.conv2d, ops.max_pool, ops.avg_pool],\n",
    "                            stride=1, padding='VALID'):\n",
    "        # 299 x 299 x 3\n",
    "        end_points['conv0'] = ops.conv2d(inputs, 32, [3, 3], stride=2,\n",
    "                                         scope='conv0')\n",
    "        # 149 x 149 x 32\n",
    "        end_points['conv1'] = ops.conv2d(end_points['conv0'], 32, [3, 3],\n",
    "                                         scope='conv1')\n",
    "        # 147 x 147 x 32\n",
    "        end_points['conv2'] = ops.conv2d(end_points['conv1'], 64, [3, 3],\n",
    "                                         padding='SAME', scope='conv2')\n",
    "        # 147 x 147 x 64\n",
    "        end_points['pool1'] = ops.max_pool(end_points['conv2'], [3, 3],\n",
    "                                           stride=2, scope='pool1')\n",
    "        # 73 x 73 x 64\n",
    "        end_points['conv3'] = ops.conv2d(end_points['pool1'], 80, [1, 1],\n",
    "                                         scope='conv3')\n",
    "        # 73 x 73 x 80.\n",
    "        end_points['conv4'] = ops.conv2d(end_points['conv3'], 192, [3, 3],\n",
    "                                         scope='conv4')\n",
    "        # 71 x 71 x 192.\n",
    "        end_points['pool2'] = ops.max_pool(end_points['conv4'], [3, 3],\n",
    "                                           stride=2, scope='pool2')\n",
    "        # 35 x 35 x 192.\n",
    "        net = end_points['pool2']\n",
    "      # Inception blocks\n",
    "      with scopes.arg_scope([ops.conv2d, ops.max_pool, ops.avg_pool],\n",
    "                            stride=1, padding='SAME'):\n",
    "        # mixed: 35 x 35 x 256.\n",
    "        with tf.variable_scope('mixed_35x35x256a'):\n",
    "          with tf.variable_scope('branch1x1'):\n",
    "            branch1x1 = ops.conv2d(net, 64, [1, 1])\n",
    "          with tf.variable_scope('branch5x5'):\n",
    "            branch5x5 = ops.conv2d(net, 48, [1, 1])\n",
    "            branch5x5 = ops.conv2d(branch5x5, 64, [5, 5])\n",
    "          with tf.variable_scope('branch3x3dbl'):\n",
    "            branch3x3dbl = ops.conv2d(net, 64, [1, 1])\n",
    "            branch3x3dbl = ops.conv2d(branch3x3dbl, 96, [3, 3])\n",
    "            branch3x3dbl = ops.conv2d(branch3x3dbl, 96, [3, 3])\n",
    "          with tf.variable_scope('branch_pool'):\n",
    "            branch_pool = ops.avg_pool(net, [3, 3])\n",
    "            branch_pool = ops.conv2d(branch_pool, 32, [1, 1])\n",
    "          net = tf.concat(axis=3, values=[branch1x1, branch5x5, branch3x3dbl, branch_pool])\n",
    "          end_points['mixed_35x35x256a'] = net\n",
    "        # mixed_1: 35 x 35 x 288.\n",
    "        with tf.variable_scope('mixed_35x35x288a'):\n",
    "          with tf.variable_scope('branch1x1'):\n",
    "            branch1x1 = ops.conv2d(net, 64, [1, 1])\n",
    "          with tf.variable_scope('branch5x5'):\n",
    "            branch5x5 = ops.conv2d(net, 48, [1, 1])\n",
    "            branch5x5 = ops.conv2d(branch5x5, 64, [5, 5])\n",
    "          with tf.variable_scope('branch3x3dbl'):\n",
    "            branch3x3dbl = ops.conv2d(net, 64, [1, 1])\n",
    "            branch3x3dbl = ops.conv2d(branch3x3dbl, 96, [3, 3])\n",
    "            branch3x3dbl = ops.conv2d(branch3x3dbl, 96, [3, 3])\n",
    "          with tf.variable_scope('branch_pool'):\n",
    "            branch_pool = ops.avg_pool(net, [3, 3])\n",
    "            branch_pool = ops.conv2d(branch_pool, 64, [1, 1])\n",
    "          net = tf.concat(axis=3, values=[branch1x1, branch5x5, branch3x3dbl, branch_pool])\n",
    "          end_points['mixed_35x35x288a'] = net\n",
    "        # mixed_2: 35 x 35 x 288.\n",
    "        with tf.variable_scope('mixed_35x35x288b'):\n",
    "          with tf.variable_scope('branch1x1'):\n",
    "            branch1x1 = ops.conv2d(net, 64, [1, 1])\n",
    "          with tf.variable_scope('branch5x5'):\n",
    "            branch5x5 = ops.conv2d(net, 48, [1, 1])\n",
    "            branch5x5 = ops.conv2d(branch5x5, 64, [5, 5])\n",
    "          with tf.variable_scope('branch3x3dbl'):\n",
    "            branch3x3dbl = ops.conv2d(net, 64, [1, 1])\n",
    "            branch3x3dbl = ops.conv2d(branch3x3dbl, 96, [3, 3])\n",
    "            branch3x3dbl = ops.conv2d(branch3x3dbl, 96, [3, 3])\n",
    "          with tf.variable_scope('branch_pool'):\n",
    "            branch_pool = ops.avg_pool(net, [3, 3])\n",
    "            branch_pool = ops.conv2d(branch_pool, 64, [1, 1])\n",
    "          net = tf.concat(axis=3, values=[branch1x1, branch5x5, branch3x3dbl, branch_pool])\n",
    "          end_points['mixed_35x35x288b'] = net\n",
    "        # mixed_3: 17 x 17 x 768.\n",
    "        with tf.variable_scope('mixed_17x17x768a'):\n",
    "          with tf.variable_scope('branch3x3'):\n",
    "            branch3x3 = ops.conv2d(net, 384, [3, 3], stride=2, padding='VALID')\n",
    "          with tf.variable_scope('branch3x3dbl'):\n",
    "            branch3x3dbl = ops.conv2d(net, 64, [1, 1])\n",
    "            branch3x3dbl = ops.conv2d(branch3x3dbl, 96, [3, 3])\n",
    "            branch3x3dbl = ops.conv2d(branch3x3dbl, 96, [3, 3],\n",
    "                                      stride=2, padding='VALID')\n",
    "          with tf.variable_scope('branch_pool'):\n",
    "            branch_pool = ops.max_pool(net, [3, 3], stride=2, padding='VALID')\n",
    "          net = tf.concat(axis=3, values=[branch3x3, branch3x3dbl, branch_pool])\n",
    "          end_points['mixed_17x17x768a'] = net\n",
    "        # mixed4: 17 x 17 x 768.\n",
    "        with tf.variable_scope('mixed_17x17x768b'):\n",
    "          with tf.variable_scope('branch1x1'):\n",
    "            branch1x1 = ops.conv2d(net, 192, [1, 1])\n",
    "          with tf.variable_scope('branch7x7'):\n",
    "            branch7x7 = ops.conv2d(net, 128, [1, 1])\n",
    "            branch7x7 = ops.conv2d(branch7x7, 128, [1, 7])\n",
    "            branch7x7 = ops.conv2d(branch7x7, 192, [7, 1])\n",
    "          with tf.variable_scope('branch7x7dbl'):\n",
    "            branch7x7dbl = ops.conv2d(net, 128, [1, 1])\n",
    "            branch7x7dbl = ops.conv2d(branch7x7dbl, 128, [7, 1])\n",
    "            branch7x7dbl = ops.conv2d(branch7x7dbl, 128, [1, 7])\n",
    "            branch7x7dbl = ops.conv2d(branch7x7dbl, 128, [7, 1])\n",
    "            branch7x7dbl = ops.conv2d(branch7x7dbl, 192, [1, 7])\n",
    "          with tf.variable_scope('branch_pool'):\n",
    "            branch_pool = ops.avg_pool(net, [3, 3])\n",
    "            branch_pool = ops.conv2d(branch_pool, 192, [1, 1])\n",
    "          net = tf.concat(axis=3, values=[branch1x1, branch7x7, branch7x7dbl, branch_pool])\n",
    "          end_points['mixed_17x17x768b'] = net\n",
    "        # mixed_5: 17 x 17 x 768.\n",
    "        with tf.variable_scope('mixed_17x17x768c'):\n",
    "          with tf.variable_scope('branch1x1'):\n",
    "            branch1x1 = ops.conv2d(net, 192, [1, 1])\n",
    "          with tf.variable_scope('branch7x7'):\n",
    "            branch7x7 = ops.conv2d(net, 160, [1, 1])\n",
    "            branch7x7 = ops.conv2d(branch7x7, 160, [1, 7])\n",
    "            branch7x7 = ops.conv2d(branch7x7, 192, [7, 1])\n",
    "          with tf.variable_scope('branch7x7dbl'):\n",
    "            branch7x7dbl = ops.conv2d(net, 160, [1, 1])\n",
    "            branch7x7dbl = ops.conv2d(branch7x7dbl, 160, [7, 1])\n",
    "            branch7x7dbl = ops.conv2d(branch7x7dbl, 160, [1, 7])\n",
    "            branch7x7dbl = ops.conv2d(branch7x7dbl, 160, [7, 1])\n",
    "            branch7x7dbl = ops.conv2d(branch7x7dbl, 192, [1, 7])\n",
    "          with tf.variable_scope('branch_pool'):\n",
    "            branch_pool = ops.avg_pool(net, [3, 3])\n",
    "            branch_pool = ops.conv2d(branch_pool, 192, [1, 1])\n",
    "          net = tf.concat(axis=3, values=[branch1x1, branch7x7, branch7x7dbl, branch_pool])\n",
    "          end_points['mixed_17x17x768c'] = net\n",
    "        # mixed_6: 17 x 17 x 768.\n",
    "        with tf.variable_scope('mixed_17x17x768d'):\n",
    "          with tf.variable_scope('branch1x1'):\n",
    "            branch1x1 = ops.conv2d(net, 192, [1, 1])\n",
    "          with tf.variable_scope('branch7x7'):\n",
    "            branch7x7 = ops.conv2d(net, 160, [1, 1])\n",
    "            branch7x7 = ops.conv2d(branch7x7, 160, [1, 7])\n",
    "            branch7x7 = ops.conv2d(branch7x7, 192, [7, 1])\n",
    "          with tf.variable_scope('branch7x7dbl'):\n",
    "            branch7x7dbl = ops.conv2d(net, 160, [1, 1])\n",
    "            branch7x7dbl = ops.conv2d(branch7x7dbl, 160, [7, 1])\n",
    "            branch7x7dbl = ops.conv2d(branch7x7dbl, 160, [1, 7])\n",
    "            branch7x7dbl = ops.conv2d(branch7x7dbl, 160, [7, 1])\n",
    "            branch7x7dbl = ops.conv2d(branch7x7dbl, 192, [1, 7])\n",
    "          with tf.variable_scope('branch_pool'):\n",
    "            branch_pool = ops.avg_pool(net, [3, 3])\n",
    "            branch_pool = ops.conv2d(branch_pool, 192, [1, 1])\n",
    "          net = tf.concat(axis=3, values=[branch1x1, branch7x7, branch7x7dbl, branch_pool])\n",
    "          end_points['mixed_17x17x768d'] = net\n",
    "        # mixed_7: 17 x 17 x 768.\n",
    "        with tf.variable_scope('mixed_17x17x768e'):\n",
    "          with tf.variable_scope('branch1x1'):\n",
    "            branch1x1 = ops.conv2d(net, 192, [1, 1])\n",
    "          with tf.variable_scope('branch7x7'):\n",
    "            branch7x7 = ops.conv2d(net, 192, [1, 1])\n",
    "            branch7x7 = ops.conv2d(branch7x7, 192, [1, 7])\n",
    "            branch7x7 = ops.conv2d(branch7x7, 192, [7, 1])\n",
    "          with tf.variable_scope('branch7x7dbl'):\n",
    "            branch7x7dbl = ops.conv2d(net, 192, [1, 1])\n",
    "            branch7x7dbl = ops.conv2d(branch7x7dbl, 192, [7, 1])\n",
    "            branch7x7dbl = ops.conv2d(branch7x7dbl, 192, [1, 7])\n",
    "            branch7x7dbl = ops.conv2d(branch7x7dbl, 192, [7, 1])\n",
    "            branch7x7dbl = ops.conv2d(branch7x7dbl, 192, [1, 7])\n",
    "          with tf.variable_scope('branch_pool'):\n",
    "            branch_pool = ops.avg_pool(net, [3, 3])\n",
    "            branch_pool = ops.conv2d(branch_pool, 192, [1, 1])\n",
    "          net = tf.concat(axis=3, values=[branch1x1, branch7x7, branch7x7dbl, branch_pool])\n",
    "          end_points['mixed_17x17x768e'] = net\n",
    "        # Auxiliary Head logits\n",
    "        aux_logits = tf.identity(end_points['mixed_17x17x768e'])\n",
    "        with tf.variable_scope('aux_logits'):\n",
    "          aux_logits = ops.avg_pool(aux_logits, [5, 5], stride=3,\n",
    "                                    padding='VALID')\n",
    "          aux_logits = ops.conv2d(aux_logits, 128, [1, 1], scope='proj')\n",
    "          # Shape of feature map before the final layer.\n",
    "          shape = aux_logits.get_shape()\n",
    "          aux_logits = ops.conv2d(aux_logits, 768, shape[1:3], stddev=0.01,\n",
    "                                  padding='VALID')\n",
    "          aux_logits = ops.flatten(aux_logits)\n",
    "          aux_logits = ops.fc(aux_logits, num_classes, activation=None,\n",
    "                              stddev=0.001, restore=restore_logits)\n",
    "          end_points['aux_logits'] = aux_logits\n",
    "        # mixed_8: 8 x 8 x 1280.\n",
    "        # Note that the scope below is not changed to not void previous\n",
    "        # checkpoints.\n",
    "        # (TODO) Fix the scope when appropriate.\n",
    "        with tf.variable_scope('mixed_17x17x1280a'):\n",
    "          with tf.variable_scope('branch3x3'):\n",
    "            branch3x3 = ops.conv2d(net, 192, [1, 1])\n",
    "            branch3x3 = ops.conv2d(branch3x3, 320, [3, 3], stride=2,\n",
    "                                   padding='VALID')\n",
    "          with tf.variable_scope('branch7x7x3'):\n",
    "            branch7x7x3 = ops.conv2d(net, 192, [1, 1])\n",
    "            branch7x7x3 = ops.conv2d(branch7x7x3, 192, [1, 7])\n",
    "            branch7x7x3 = ops.conv2d(branch7x7x3, 192, [7, 1])\n",
    "            branch7x7x3 = ops.conv2d(branch7x7x3, 192, [3, 3],\n",
    "                                     stride=2, padding='VALID')\n",
    "          with tf.variable_scope('branch_pool'):\n",
    "            branch_pool = ops.max_pool(net, [3, 3], stride=2, padding='VALID')\n",
    "          net = tf.concat(axis=3, values=[branch3x3, branch7x7x3, branch_pool])\n",
    "          end_points['mixed_17x17x1280a'] = net\n",
    "        # mixed_9: 8 x 8 x 2048.\n",
    "        with tf.variable_scope('mixed_8x8x2048a'):\n",
    "          with tf.variable_scope('branch1x1'):\n",
    "            branch1x1 = ops.conv2d(net, 320, [1, 1])\n",
    "          with tf.variable_scope('branch3x3'):\n",
    "            branch3x3 = ops.conv2d(net, 384, [1, 1])\n",
    "            branch3x3 = tf.concat(axis=3, values=[ops.conv2d(branch3x3, 384, [1, 3]),\n",
    "                                                  ops.conv2d(branch3x3, 384, [3, 1])])\n",
    "          with tf.variable_scope('branch3x3dbl'):\n",
    "            branch3x3dbl = ops.conv2d(net, 448, [1, 1])\n",
    "            branch3x3dbl = ops.conv2d(branch3x3dbl, 384, [3, 3])\n",
    "            branch3x3dbl = tf.concat(axis=3, values=[ops.conv2d(branch3x3dbl, 384, [1, 3]),\n",
    "                                                     ops.conv2d(branch3x3dbl, 384, [3, 1])])\n",
    "          with tf.variable_scope('branch_pool'):\n",
    "            branch_pool = ops.avg_pool(net, [3, 3])\n",
    "            branch_pool = ops.conv2d(branch_pool, 192, [1, 1])\n",
    "          net = tf.concat(axis=3, values=[branch1x1, branch3x3, branch3x3dbl, branch_pool])\n",
    "          end_points['mixed_8x8x2048a'] = net\n",
    "        # mixed_10: 8 x 8 x 2048.\n",
    "        with tf.variable_scope('mixed_8x8x2048b'):\n",
    "          with tf.variable_scope('branch1x1'):\n",
    "            branch1x1 = ops.conv2d(net, 320, [1, 1])\n",
    "          with tf.variable_scope('branch3x3'):\n",
    "            branch3x3 = ops.conv2d(net, 384, [1, 1])\n",
    "            branch3x3 = tf.concat(axis=3, values=[ops.conv2d(branch3x3, 384, [1, 3]),\n",
    "                                                  ops.conv2d(branch3x3, 384, [3, 1])])\n",
    "          with tf.variable_scope('branch3x3dbl'):\n",
    "            branch3x3dbl = ops.conv2d(net, 448, [1, 1])\n",
    "            branch3x3dbl = ops.conv2d(branch3x3dbl, 384, [3, 3])\n",
    "            branch3x3dbl = tf.concat(axis=3, values=[ops.conv2d(branch3x3dbl, 384, [1, 3]),\n",
    "                                                     ops.conv2d(branch3x3dbl, 384, [3, 1])])\n",
    "          with tf.variable_scope('branch_pool'):\n",
    "            branch_pool = ops.avg_pool(net, [3, 3])\n",
    "            branch_pool = ops.conv2d(branch_pool, 192, [1, 1])\n",
    "          net = tf.concat(axis=3, values=[branch1x1, branch3x3, branch3x3dbl, branch_pool])\n",
    "          end_points['mixed_8x8x2048b'] = net\n",
    "        # Final pooling and prediction\n",
    "        with tf.variable_scope('logits'):\n",
    "          shape = net.get_shape()\n",
    "          net = ops.avg_pool(net, shape[1:3], padding='VALID', scope='pool')\n",
    "          # 1 x 1 x 2048\n",
    "          net = ops.dropout(net, dropout_keep_prob, scope='dropout')\n",
    "          net = ops.flatten(net, scope='flatten')\n",
    "          # 2048\n",
    "          logits = ops.fc(net, num_classes, activation=None, scope='logits',\n",
    "                          restore=restore_logits)\n",
    "          # 1000\n",
    "          end_points['logits'] = logits\n",
    "          end_points['predictions'] = tf.nn.softmax(logits, name='predictions')\n",
    "      return logits, end_points\n",
    "\n",
    "\n",
    "def inception_v3_parameters(weight_decay=0.00004, stddev=0.1,\n",
    "                            batch_norm_decay=0.9997, batch_norm_epsilon=0.001):\n",
    "  \"\"\"Yields the scope with the default parameters for inception_v3.\n",
    "\n",
    "  Args:\n",
    "    weight_decay: the weight decay for weights variables.\n",
    "    stddev: standard deviation of the truncated guassian weight distribution.\n",
    "    batch_norm_decay: decay for the moving average of batch_norm momentums.\n",
    "    batch_norm_epsilon: small float added to variance to avoid dividing by zero.\n",
    "\n",
    "  Yields:\n",
    "    a arg_scope with the parameters needed for inception_v3.\n",
    "  \"\"\"\n",
    "  # Set weight_decay for weights in Conv and FC layers.\n",
    "  with scopes.arg_scope([ops.conv2d, ops.fc],\n",
    "                        weight_decay=weight_decay):\n",
    "    # Set stddev, activation and parameters for batch_norm.\n",
    "    with scopes.arg_scope([ops.conv2d],\n",
    "                          stddev=stddev,\n",
    "                          activation=tf.nn.relu,\n",
    "                          batch_norm_params={\n",
    "                              'decay': batch_norm_decay,\n",
    "                              'epsilon': batch_norm_epsilon}) as arg_scope:\n",
    "      yield arg_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "tf.app.flags.DEFINE_string('train_dir', '/tmp/imagenet_train',\n",
    "                           \"\"\"Directory where to write event logs \"\"\"\n",
    "                           \"\"\"and checkpoint.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('max_steps', 10000000,\n",
    "                            \"\"\"Number of batches to run.\"\"\")\n",
    "tf.app.flags.DEFINE_string('subset', 'train',\n",
    "                           \"\"\"Either 'train' or 'validation'.\"\"\")\n",
    "\n",
    "# Flags governing the hardware employed for running TensorFlow.\n",
    "tf.app.flags.DEFINE_integer('num_gpus', 1,\n",
    "                            \"\"\"How many GPUs to use.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('log_device_placement', False,\n",
    "                            \"\"\"Whether to log device placement.\"\"\")\n",
    "\n",
    "# Flags governing the type of training.\n",
    "tf.app.flags.DEFINE_boolean('fine_tune', False,\n",
    "                            \"\"\"If set, randomly initialize the final layer \"\"\"\n",
    "                            \"\"\"of weights in order to train the network on a \"\"\"\n",
    "                            \"\"\"new task.\"\"\")\n",
    "tf.app.flags.DEFINE_string('pretrained_model_checkpoint_path', '',\n",
    "                           \"\"\"If specified, restore this pretrained model \"\"\"\n",
    "                           \"\"\"before beginning any training.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.app.flags.DEFINE_float('initial_learning_rate', 0.1,\n",
    "                          \"\"\"Initial learning rate.\"\"\")\n",
    "tf.app.flags.DEFINE_float('num_epochs_per_decay', 30.0,\n",
    "                          \"\"\"Epochs after which learning rate decays.\"\"\")\n",
    "tf.app.flags.DEFINE_float('learning_rate_decay_factor', 0.16,\n",
    "                          \"\"\"Learning rate decay factor.\"\"\")\n",
    "\n",
    "# Constants dictating the learning rate schedule.\n",
    "RMSPROP_DECAY = 0.9                # Decay term for RMSProp.\n",
    "RMSPROP_MOMENTUM = 0.9             # Momentum in RMSProp.\n",
    "RMSPROP_EPSILON = 1.0              # Epsilon term for RMSProp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _tower_loss(images, labels, num_classes, scope, reuse_variables=None):\n",
    "  \"\"\"Calculate the total loss on a single tower running the ImageNet model.\n",
    "\n",
    "  We perform 'batch splitting'. This means that we cut up a batch across\n",
    "  multiple GPUs. For instance, if the batch size = 32 and num_gpus = 2,\n",
    "  then each tower will operate on an batch of 16 images.\n",
    "\n",
    "  Args:\n",
    "    images: Images. 4D tensor of size [batch_size, FLAGS.image_size,\n",
    "                                       FLAGS.image_size, 3].\n",
    "    labels: 1-D integer Tensor of [batch_size].\n",
    "    num_classes: number of classes\n",
    "    scope: unique prefix string identifying the ImageNet tower, e.g.\n",
    "      'tower_0'.\n",
    "\n",
    "  Returns:\n",
    "     Tensor of shape [] containing the total loss for a batch of data\n",
    "  \"\"\"\n",
    "  # When fine-tuning a model, we do not restore the logits but instead we\n",
    "  # randomly initialize the logits. The number of classes in the output of the\n",
    "  # logit is the number of classes in specified Dataset.\n",
    "  restore_logits = not FLAGS.fine_tune\n",
    "\n",
    "  # Build inference Graph.\n",
    "  with tf.variable_scope(tf.get_variable_scope(), reuse=reuse_variables):\n",
    "    logits = inception.inference(images, num_classes, for_training=True,\n",
    "                                 restore_logits=restore_logits,\n",
    "                                 scope=scope)\n",
    "\n",
    "  # Build the portion of the Graph calculating the losses. Note that we will\n",
    "  # assemble the total_loss using a custom function below.\n",
    "  split_batch_size = images.get_shape().as_list()[0]\n",
    "  inception.loss(logits, labels, batch_size=split_batch_size)\n",
    "\n",
    "  # Assemble all of the losses for the current tower only.\n",
    "  losses = tf.get_collection(slim.losses.LOSSES_COLLECTION, scope)\n",
    "\n",
    "  # Calculate the total loss for the current tower.\n",
    "  regularization_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "  total_loss = tf.add_n(losses + regularization_losses, name='total_loss')\n",
    "\n",
    "  # Compute the moving average of all individual losses and the total loss.\n",
    "  loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\n",
    "  loss_averages_op = loss_averages.apply(losses + [total_loss])\n",
    "\n",
    "  # Attach a scalar summmary to all individual losses and the total loss; do the\n",
    "  # same for the averaged version of the losses.\n",
    "  for l in losses + [total_loss]:\n",
    "    # Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training\n",
    "    # session. This helps the clarity of presentation on TensorBoard.\n",
    "    loss_name = re.sub('%s_[0-9]*/' % inception.TOWER_NAME, '', l.op.name)\n",
    "    # Name each loss as '(raw)' and name the moving average version of the loss\n",
    "    # as the original loss name.\n",
    "    tf.summary.scalar(loss_name +' (raw)', l)\n",
    "    tf.summary.scalar(loss_name, loss_averages.average(l))\n",
    "\n",
    "  with tf.control_dependencies([loss_averages_op]):\n",
    "    total_loss = tf.identity(total_loss)\n",
    "  return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _average_gradients(tower_grads):\n",
    "  \"\"\"Calculate the average gradient for each shared variable across all towers.\n",
    "\n",
    "  Note that this function provides a synchronization point across all towers.\n",
    "\n",
    "  Args:\n",
    "    tower_grads: List of lists of (gradient, variable) tuples. The outer list\n",
    "      is over individual gradients. The inner list is over the gradient\n",
    "      calculation for each tower.\n",
    "  Returns:\n",
    "     List of pairs of (gradient, variable) where the gradient has been averaged\n",
    "     across all towers.\n",
    "  \"\"\"\n",
    "  average_grads = []\n",
    "  for grad_and_vars in zip(*tower_grads):\n",
    "    # Note that each grad_and_vars looks like the following:\n",
    "    #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "    grads = []\n",
    "    for g, _ in grad_and_vars:\n",
    "      # Add 0 dimension to the gradients to represent the tower.\n",
    "      expanded_g = tf.expand_dims(g, 0)\n",
    "\n",
    "      # Append on a 'tower' dimension which we will average over below.\n",
    "      grads.append(expanded_g)\n",
    "\n",
    "    # Average over the 'tower' dimension.\n",
    "    grad = tf.concat(axis=0, values=grads)\n",
    "    grad = tf.reduce_mean(grad, 0)\n",
    "\n",
    "    # Keep in mind that the Variables are redundant because they are shared\n",
    "    # across towers. So .. we will just return the first tower's pointer to\n",
    "    # the Variable.\n",
    "    v = grad_and_vars[0][1]\n",
    "    grad_and_var = (grad, v)\n",
    "    average_grads.append(grad_and_var)\n",
    "  return average_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(dataset):\n",
    "  \"\"\"Train on dataset for a number of steps.\"\"\"\n",
    "  with tf.Graph().as_default(), tf.device('/cpu:0'):\n",
    "    # Create a variable to count the number of train() calls. This equals the\n",
    "    # number of batches processed * FLAGS.num_gpus.\n",
    "    global_step = tf.get_variable(\n",
    "        'global_step', [],\n",
    "        initializer=tf.constant_initializer(0), trainable=False)\n",
    "\n",
    "    # Calculate the learning rate schedule.\n",
    "    num_batches_per_epoch = (dataset.num_examples_per_epoch() /\n",
    "                             FLAGS.batch_size)\n",
    "    decay_steps = int(num_batches_per_epoch * FLAGS.num_epochs_per_decay)\n",
    "\n",
    "    # Decay the learning rate exponentially based on the number of steps.\n",
    "    lr = tf.train.exponential_decay(FLAGS.initial_learning_rate,\n",
    "                                    global_step,\n",
    "                                    decay_steps,\n",
    "                                    FLAGS.learning_rate_decay_factor,\n",
    "                                    staircase=True)\n",
    "\n",
    "    # Create an optimizer that performs gradient descent.\n",
    "    opt = tf.train.RMSPropOptimizer(lr, RMSPROP_DECAY,\n",
    "                                    momentum=RMSPROP_MOMENTUM,\n",
    "                                    epsilon=RMSPROP_EPSILON)\n",
    "\n",
    "    # Get images and labels for ImageNet and split the batch across GPUs.\n",
    "    assert FLAGS.batch_size % FLAGS.num_gpus == 0, (\n",
    "        'Batch size must be divisible by number of GPUs')\n",
    "    split_batch_size = int(FLAGS.batch_size / FLAGS.num_gpus)\n",
    "\n",
    "    # Override the number of preprocessing threads to account for the increased\n",
    "    # number of GPU towers.\n",
    "    num_preprocess_threads = FLAGS.num_preprocess_threads * FLAGS.num_gpus\n",
    "    images, labels = image_processing.distorted_inputs(\n",
    "        dataset,\n",
    "        num_preprocess_threads=num_preprocess_threads)\n",
    "\n",
    "    input_summaries = copy.copy(tf.get_collection(tf.GraphKeys.SUMMARIES))\n",
    "\n",
    "    # Number of classes in the Dataset label set plus 1.\n",
    "    # Label 0 is reserved for an (unused) background class.\n",
    "    num_classes = dataset.num_classes() + 1\n",
    "\n",
    "     # Split the batch of images and labels for towers.\n",
    "    images_splits = tf.split(axis=0, num_or_size_splits=FLAGS.num_gpus, value=images)\n",
    "    labels_splits = tf.split(axis=0, num_or_size_splits=FLAGS.num_gpus, value=labels)\n",
    "\n",
    "    # Calculate the gradients for each model tower.\n",
    "    tower_grads = []\n",
    "    reuse_variables = None\n",
    "    for i in range(FLAGS.num_gpus):\n",
    "      with tf.device('/gpu:%d' % i):\n",
    "        with tf.name_scope('%s_%d' % (inception.TOWER_NAME, i)) as scope:\n",
    "          # Force all Variables to reside on the CPU.\n",
    "          with slim.arg_scope([slim.variables.variable], device='/cpu:0'):\n",
    "            # Calculate the loss for one tower of the ImageNet model. This\n",
    "            # function constructs the entire ImageNet model but shares the\n",
    "            # variables across all towers.\n",
    "            loss = _tower_loss(images_splits[i], labels_splits[i], num_classes,\n",
    "                               scope, reuse_variables)\n",
    "\n",
    "          # Reuse variables for the next tower.\n",
    "          reuse_variables = True\n",
    "\n",
    "          # Retain the summaries from the final tower.\n",
    "          summaries = tf.get_collection(tf.GraphKeys.SUMMARIES, scope)\n",
    "\n",
    "          # Retain the Batch Normalization updates operations only from the\n",
    "          # final tower. Ideally, we should grab the updates from all towers\n",
    "          # but these stats accumulate extremely fast so we can ignore the\n",
    "          # other stats from the other towers without significant detriment.\n",
    "          batchnorm_updates = tf.get_collection(slim.ops.UPDATE_OPS_COLLECTION,\n",
    "                                                scope)\n",
    "\n",
    "          # Calculate the gradients for the batch of data on this ImageNet\n",
    "          # tower.\n",
    "          grads = opt.compute_gradients(loss)\n",
    "\n",
    "          # Keep track of the gradients across all towers.\n",
    "          tower_grads.append(grads)\n",
    "\n",
    "    # We must calculate the mean of each gradient. Note that this is the\n",
    "    # synchronization point across all towers.\n",
    "    grads = _average_gradients(tower_grads)\n",
    "\n",
    "    # Add a summaries for the input processing and global_step.\n",
    "    summaries.extend(input_summaries)\n",
    "\n",
    "    # Add a summary to track the learning rate.\n",
    "    summaries.append(tf.summary.scalar('learning_rate', lr))\n",
    "\n",
    "    # Add histograms for gradients.\n",
    "    for grad, var in grads:\n",
    "      if grad is not None:\n",
    "        summaries.append(\n",
    "            tf.summary.histogram(var.op.name + '/gradients', grad))\n",
    "\n",
    "    # Apply the gradients to adjust the shared variables.\n",
    "    apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "    # Add histograms for trainable variables.\n",
    "    for var in tf.trainable_variables():\n",
    "      summaries.append(tf.summary.histogram(var.op.name, var))\n",
    "\n",
    "    # Track the moving averages of all trainable variables.\n",
    "    # Note that we maintain a \"double-average\" of the BatchNormalization\n",
    "    # global statistics. This is more complicated then need be but we employ\n",
    "    # this for backward-compatibility with our previous models.\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(\n",
    "        inception.MOVING_AVERAGE_DECAY, global_step)\n",
    "\n",
    "    # Another possibility is to use tf.slim.get_variables().\n",
    "    variables_to_average = (tf.trainable_variables() +\n",
    "                            tf.moving_average_variables())\n",
    "    variables_averages_op = variable_averages.apply(variables_to_average)\n",
    "\n",
    "    # Group all updates to into a single train op.\n",
    "    batchnorm_updates_op = tf.group(*batchnorm_updates)\n",
    "    train_op = tf.group(apply_gradient_op, variables_averages_op,\n",
    "                        batchnorm_updates_op)\n",
    "\n",
    "    # Create a saver.\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "    # Build the summary operation from the last tower summaries.\n",
    "    summary_op = tf.summary.merge(summaries)\n",
    "\n",
    "    # Build an initialization operation to run below.\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start running operations on the Graph. allow_soft_placement must be set to\n",
    "    # True to build towers on GPU, as some of the ops do not have GPU\n",
    "    # implementations.\n",
    "    sess = tf.Session(config=tf.ConfigProto(\n",
    "        allow_soft_placement=True,\n",
    "        log_device_placement=FLAGS.log_device_placement))\n",
    "    sess.run(init)\n",
    "\n",
    "    if FLAGS.pretrained_model_checkpoint_path:\n",
    "      assert tf.gfile.Exists(FLAGS.pretrained_model_checkpoint_path)\n",
    "      variables_to_restore = tf.get_collection(\n",
    "          slim.variables.VARIABLES_TO_RESTORE)\n",
    "      restorer = tf.train.Saver(variables_to_restore)\n",
    "      restorer.restore(sess, FLAGS.pretrained_model_checkpoint_path)\n",
    "      print('%s: Pre-trained model restored from %s' %\n",
    "            (datetime.now(), FLAGS.pretrained_model_checkpoint_path))\n",
    "\n",
    "    # Start the queue runners.\n",
    "    tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "    summary_writer = tf.summary.FileWriter(\n",
    "        FLAGS.train_dir,\n",
    "        graph=sess.graph)\n",
    "\n",
    "    for step in range(FLAGS.max_steps):\n",
    "      start_time = time.time()\n",
    "      _, loss_value = sess.run([train_op, loss])\n",
    "      duration = time.time() - start_time\n",
    "\n",
    "      assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "\n",
    "      if step % 10 == 0:\n",
    "        examples_per_sec = FLAGS.batch_size / float(duration)\n",
    "        format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n",
    "                      'sec/batch)')\n",
    "        print(format_str % (datetime.now(), step, loss_value,\n",
    "                            examples_per_sec, duration))\n",
    "\n",
    "      if step % 100 == 0:\n",
    "        summary_str = sess.run(summary_op)\n",
    "        summary_writer.add_summary(summary_str, step)\n",
    "\n",
    "      # Save the model checkpoint periodically.\n",
    "      if step % 5000 == 0 or (step + 1) == FLAGS.max_steps:\n",
    "        checkpoint_path = os.path.join(FLAGS.train_dir, 'model.ckpt')\n",
    "        saver.save(sess, checkpoint_path, global_step=step)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
