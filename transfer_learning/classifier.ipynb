{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tqdm\n",
    "#!pip install progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from getvector import getvector\n",
    "from tensorflow.python.platform import gfile\n",
    "from progress.bar import Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_inputs = []\n",
    "data_labels = []\n",
    "\n",
    "# Checking if the 2048-dimensional vector representations of the training images are already available\n",
    "if os.path.isfile('./data_inputs.txt') and os.path.isfile('./data_labels.txt'):\n",
    "\tdata_inputs = np.loadtxt('data_inputs.txt')\n",
    "\tdata_labels = np.loadtxt('data_labels.txt')\n",
    "\n",
    "else: \n",
    "\t# add in your images here if you want to train the model on your own images\n",
    "\timage_dir = './train'\n",
    "\tfile_list = []\n",
    "\tfile_glob = os.path.join(image_dir, '*.jpg');\n",
    "\tfile_list.extend(gfile.Glob(file_glob))\n",
    "\n",
    "\t# I only used 300 images from the cats and dogs dataset\n",
    "\tfile_list = file_list[0:300]\n",
    "\tbar = Bar('Inception-V3 is processing images:', max=300)\n",
    "\tfor file_name in file_list:\n",
    "\t\tdata_inputs.append(getvector(file_name))\n",
    "\t\tif 'cat' in file_name:\n",
    "\t\t\tdata_labels.append([1, 0])\n",
    "\t\telse:\n",
    "\t\t\tdata_labels.append([0, 1])\n",
    "\t\tbar.next()\n",
    "\tbar.finish()\n",
    "\n",
    "\tnp.savetxt('data_inputs.txt', data_inputs)\n",
    "\tnp.savetxt('data_labels.txt', data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting into train, val, and test\n",
    "train_inputs, valtest_inputs, train_labels, valtest_labels = train_test_split(data_inputs, data_labels, test_size=0.3, random_state=42)\n",
    "val_inputs, test_inputs, val_labels, test_labels = train_test_split(valtest_inputs, valtest_labels, test_size=0.4, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting hyperparameters\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "log_batch_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# useful info\n",
    "n_features = np.size(train_inputs, 1)\n",
    "n_labels = np.size(train_labels, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholders for input features and labels\n",
    "inputs = tf.placeholder(tf.float32, (None, n_features))\n",
    "labels = tf.placeholder(tf.float32, (None, n_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal((n_features, n_labels), stddev=0.1), name='weights')\n",
    "bias = tf.Variable(tf.zeros(n_labels), name='bias')\n",
    "tf.add_to_collection('vars', weights)\n",
    "tf.add_to_collection('vars', bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up operation in fully connected layer\n",
    "logits = tf.add(tf.matmul(inputs, weights), bias)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "tf.add_to_collection('pred', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining loss of network\n",
    "difference = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "loss = tf.reduce_sum(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting optimiser\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define accuracy\n",
    "is_correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32))\n",
    "\n",
    "saver = tf.train.Saver((weights, bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1/10: 100%|██████████| 4/4 [00:00<00:00, 312.00batches/s]\n",
      "Epoch  2/10: 100%|██████████| 4/4 [00:00<00:00, 1203.96batches/s]\n",
      "Epoch  3/10: 100%|██████████| 4/4 [00:00<00:00, 1560.24batches/s]\n",
      "Epoch  4/10: 100%|██████████| 4/4 [00:00<00:00, 1640.32batches/s]\n",
      "Epoch  5/10: 100%|██████████| 4/4 [00:00<00:00, 1577.99batches/s]\n",
      "Epoch  6/10: 100%|██████████| 4/4 [00:00<00:00, 580.23batches/s]\n",
      "Epoch  7/10: 100%|██████████| 4/4 [00:00<00:00, 1284.23batches/s]\n",
      "Epoch  8/10: 100%|██████████| 4/4 [00:00<00:00, 1405.01batches/s]\n",
      "Epoch  9/10: 100%|██████████| 4/4 [00:00<00:00, 830.60batches/s]\n",
      "Epoch 10/10: 100%|██████████| 4/4 [00:00<00:00, 1360.35batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After epoch 1, Loss: 19.389720916748047, Accuracy: 0.7777777910232544\n",
      "After epoch 2, Loss: 4.064395427703857, Accuracy: 0.9629629850387573\n",
      "After epoch 3, Loss: 7.375451564788818, Accuracy: 0.9814814925193787\n",
      "After epoch 4, Loss: 5.414290428161621, Accuracy: 0.9814814925193787\n",
      "After epoch 5, Loss: 1.9722354412078857, Accuracy: 0.9814814925193787\n",
      "After epoch 6, Loss: 2.9749677181243896, Accuracy: 0.9814814925193787\n",
      "After epoch 7, Loss: 5.313618183135986, Accuracy: 0.9629629850387573\n",
      "After epoch 8, Loss: 3.679164171218872, Accuracy: 0.9814814925193787\n",
      "After epoch 9, Loss: 1.7606784105300903, Accuracy: 0.9814814925193787\n",
      "After epoch 10, Loss: 1.0419766902923584, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Run tensorflow session\n",
    "with tf.Session() as sess:\n",
    "\tinit = tf.global_variables_initializer()\n",
    "\tsess.run(init)\n",
    "\n",
    "\t# Running the training in batches \n",
    "\tbatch_count = int(math.ceil(len(train_inputs)/batch_size))\n",
    "\n",
    "\tfor epoch_i in range(epochs):\n",
    "\t\tbatches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(epoch_i+1, epochs), unit='batches')\n",
    "\t\t# The training cycle\n",
    "\t\tfor batch_i in batches_pbar:\n",
    "\t\t\t# Get a batch of training features and labels\n",
    "\t\t\tbatch_start = batch_i*batch_size\n",
    "\t\t\tbatch_inputs = train_inputs[batch_start:batch_start + batch_size]\n",
    "\t\t\tbatch_labels = train_labels[batch_start:batch_start + batch_size]\n",
    "\t\t\t# Run optimizer\n",
    "\t\t\t_ = sess.run(optimizer, feed_dict={inputs: batch_inputs, labels: batch_labels})\n",
    "\t\t\n",
    "\n",
    "\t\t# Check accuracy against validation data\n",
    "\t\tval_accuracy, val_loss = sess.run([accuracy, loss], feed_dict={inputs: val_inputs, labels: val_labels})\n",
    "\t\tprint(\"After epoch {}, Loss: {}, Accuracy: {}\".format(epoch_i+1, val_loss, val_accuracy))\n",
    "\n",
    "\tg = tf.get_default_graph()\n",
    "\tsaver.save(sess, './testsave')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prediction, file_name = 'cat.jpg'):\n",
    "    #try: \n",
    "    #    file_name = 'cat.jpg'\n",
    "    #except IndexError:\n",
    "    #    print ('please enter image file path.........')\n",
    "    #    exit()\n",
    "    image_input = getvector(file_name).reshape((1,2048))\n",
    "    if 'cat' in file_name:\n",
    "        image_label = [[1, 0]]\n",
    "    else:\n",
    "        image_label = [[0, 1]]\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        new_saver = tf.train.import_meta_graph('testsave.meta')\n",
    "        new_saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "\n",
    "        pred = sess.run(prediction, feed_dict={inputs: image_input})\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/grupoavatar/inf659-inception/transfer_learning/inception_v3.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./testsave\n",
      "Predict: cat.jpg\n",
      "\n",
      "It's a cat: 0.9999955892562866, It's a dog: 4.357814759714529e-06\n",
      "INFO:tensorflow:Restoring parameters from /home/grupoavatar/inf659-inception/transfer_learning/inception_v3.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./testsave\n",
      "Predict: cat.jpg\n",
      "\n",
      "It's a cat: 0.0003192309523001313, It's a dog: 0.999680757522583\n"
     ]
    }
   ],
   "source": [
    "pred = predict(prediction, 'cat.jpg')\n",
    "print('Predict: cat.jpg\\n', )\n",
    "print ('It\\'s a cat: {}, It\\'s a dog: {}'.format(pred[0][0], pred[0][1]))\n",
    "\n",
    "\n",
    "pred = predict(prediction, 'dog.jpg')\n",
    "print('Predict: dog.jpg\\n', )\n",
    "print ('It\\'s a cat: {}, It\\'s a dog: {}'.format(pred[0][0], pred[0][1]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
